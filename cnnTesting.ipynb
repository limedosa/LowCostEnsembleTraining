{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (10000, 32, 32, 3), Labels shape: (10000,)\n",
      "Pixel value range: Min=0.0, Max=1.0\n",
      "Label Names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "SHAPE IMAGE: (32, 32, 3)\n",
      "One hot encoded categorical label example: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# path to file\n",
    "dataFile = './cifar10/test_batch'\n",
    "metaFile = './cifar10/batches.meta'\n",
    "\n",
    "def plottingModel():\n",
    "    # Plot accuracy\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Model Loss')\n",
    "    plt.show()\n",
    "\n",
    "# loading CIFAR-10 data & metadata\n",
    "def loadData(fileName, normalize=True):\n",
    "    with open(fileName, 'rb') as f:\n",
    "        dataDict = pickle.load(f, encoding='bytes')\n",
    "        if b'data' in dataDict:\n",
    "            data = dataDict[b'data']\n",
    "            labels = dataDict[b'labels']\n",
    "            # reshaping & transposing to correct dimensions\n",
    "            images = data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "            # normalizing pixel values between range [0, 1]\n",
    "            if normalize:\n",
    "                images = images / 255.0\n",
    "            return images, np.array(labels)\n",
    "        if b'label_names' in dataDict:\n",
    "            return [name.decode('utf-8') for name in dataDict[b'label_names']]\n",
    "\n",
    "# load data & metadata\n",
    "images, labels = loadData(dataFile)\n",
    "labelNames = loadData(metaFile)\n",
    "imageShape = images[0].shape\n",
    "print(f\"Data shape: {images.shape}, Labels shape: {labels.shape}\")\n",
    "print(f\"Pixel value range: Min={images.min()}, Max={images.max()}\")\n",
    "print(f\"Label Names: {labelNames}\")\n",
    "print(f'SHAPE IMAGE: {imageShape}')\n",
    "# print(f'Image example:{images[0]}')\n",
    "\n",
    "\n",
    "def displayImages(images, labels, labelNames, numImages=5):\n",
    "    \"\"\"displayes first few images w/ labels\n",
    "    \"\"\"\n",
    "    for i in range(numImages):\n",
    "        plt.imshow((images[i] * 255).astype('uint8'))  # Scale back to [0, 255] for display\n",
    "        plt.title(labelNames[labels[i]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "def displayRandomGrid(images, labels, labelNames, rows=5, cols=5):\n",
    "    \"\"\"\n",
    "    displays a random grid of imgs\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    randomIdx = np.random.randint(0, len(images), rows * cols)\n",
    "    for i, idx in enumerate(randomIdx):\n",
    "        fig.add_subplot(rows, cols, i + 1)\n",
    "        plt.imshow((images[idx] * 255).astype('uint8'))  # Scale back to [0, 255] for display\n",
    "        plt.title(labelNames[labels[idx]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# # displays:\n",
    "# displayImages(images, labels, labelNames)\n",
    "# displayRandomGrid(images, labels, labelNames)\n",
    "\n",
    "uniqueLabels= int(len(np.unique(labels)))\n",
    "labelsCategorical = to_categorical(labels, num_classes=uniqueLabels)\n",
    "print(\"One hot encoded categorical label example:\",labelsCategorical[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First convolutional block\n",
    "model.add(Conv2D(128, kernel_size=3, activation=\"relu\", input_shape=imageShape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(Conv2D(256, kernel_size=3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Third convolutional block\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Flatten and dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - accuracy: 0.3059 - loss: 2.4945 - val_accuracy: 0.2020 - val_loss: 2.3990\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 66ms/step - accuracy: 0.4850 - loss: 1.6255 - val_accuracy: 0.2407 - val_loss: 2.3030\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.5515 - loss: 1.3650 - val_accuracy: 0.3810 - val_loss: 1.8333\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.5878 - loss: 1.2629 - val_accuracy: 0.4973 - val_loss: 1.4921\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.6213 - loss: 1.1412 - val_accuracy: 0.5087 - val_loss: 1.5018\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.6286 - loss: 1.0838 - val_accuracy: 0.4640 - val_loss: 1.7467\n",
      "313/313 - 4s - 14ms/step - accuracy: 0.5460 - loss: 1.3290\n",
      "Test Accuracy: 0.5460\n",
      "MAX Validation Accuracy 0.5086666941642761\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(128, kernel_size=3, activation=\"relu\", input_shape=imageShape))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) #connects convolution and dense layer\n",
    "model.add(Dense(10, activation='softmax')) #10 probs added to probabilities\n",
    "\n",
    "#compile model using accuracy\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labelsCategorical, random_state=0, train_size=.7, shuffle=True)\n",
    "#introducing early stopping for overfitting\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "#training model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[earlyStopping])\n",
    "test_loss, test_acc = model.evaluate(images, labelsCategorical, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"MAX Validation Accuracy\", max(list(history.history['val_accuracy'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max pool 3,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 58ms/step - accuracy: 0.1744 - loss: 2.5005 - val_accuracy: 0.3663 - val_loss: 1.8202\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.3550 - loss: 1.8388 - val_accuracy: 0.4410 - val_loss: 1.7020\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.4225 - loss: 1.7022 - val_accuracy: 0.4627 - val_loss: 1.5801\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.4489 - loss: 1.6315 - val_accuracy: 0.4507 - val_loss: 1.6200\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.4840 - loss: 1.5574 - val_accuracy: 0.4927 - val_loss: 1.5495\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.4982 - loss: 1.5413 - val_accuracy: 0.4617 - val_loss: 1.6075\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.5280 - loss: 1.4693 - val_accuracy: 0.4997 - val_loss: 1.5321\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.5490 - loss: 1.4309 - val_accuracy: 0.5183 - val_loss: 1.5392\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.5591 - loss: 1.4110 - val_accuracy: 0.5403 - val_loss: 1.4784\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - accuracy: 0.5641 - loss: 1.3655 - val_accuracy: 0.5510 - val_loss: 1.4529\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.5784 - loss: 1.3321 - val_accuracy: 0.5283 - val_loss: 1.5199\n",
      "Epoch 12/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.5960 - loss: 1.3173 - val_accuracy: 0.5430 - val_loss: 1.4751\n",
      "313/313 - 5s - 17ms/step - accuracy: 0.6258 - loss: 1.2659\n",
      "Test Accuracy: 0.6258\n",
      "MAX Validation Accuracy 0.5509999990463257\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=3, activation=\"relu\", input_shape=imageShape))\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#compile model using accuracy\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labelsCategorical, random_state=0, train_size=.7, shuffle=True)\n",
    "#introducing early stopping for overfitting\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "#training model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[earlyStopping])\n",
    "test_loss, test_acc = model.evaluate(images, labelsCategorical, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"MAX Validation Accuracy\", max(list(history.history['val_accuracy'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No max pool at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 73ms/step - accuracy: 0.2066 - loss: 2.4245 - val_accuracy: 0.3807 - val_loss: 1.8924\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 70ms/step - accuracy: 0.3463 - loss: 1.9254 - val_accuracy: 0.3793 - val_loss: 1.8452\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 70ms/step - accuracy: 0.3963 - loss: 1.8165 - val_accuracy: 0.3977 - val_loss: 1.7684\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 79ms/step - accuracy: 0.4092 - loss: 1.7838 - val_accuracy: 0.4253 - val_loss: 1.7240\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.4287 - loss: 1.7381 - val_accuracy: 0.4557 - val_loss: 1.7045\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 83ms/step - accuracy: 0.4535 - loss: 1.6986 - val_accuracy: 0.4403 - val_loss: 1.7053\n",
      "Epoch 7/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.4671 - loss: 1.6585 - val_accuracy: 0.4330 - val_loss: 1.6965\n",
      "Epoch 8/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.4668 - loss: 1.6512 - val_accuracy: 0.4520 - val_loss: 1.7001\n",
      "Epoch 9/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.4652 - loss: 1.6506 - val_accuracy: 0.4580 - val_loss: 1.6820\n",
      "Epoch 10/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - accuracy: 0.4699 - loss: 1.6412 - val_accuracy: 0.4523 - val_loss: 1.7346\n",
      "Epoch 11/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.4806 - loss: 1.6335 - val_accuracy: 0.4473 - val_loss: 1.7398\n",
      "313/313 - 6s - 21ms/step - accuracy: 0.5087 - loss: 1.5656\n",
      "Test Accuracy: 0.5087\n",
      "MAX Validation Accuracy 0.4580000042915344\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=3, activation=\"relu\", input_shape=imageShape))\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#compile model using accuracy\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labelsCategorical, random_state=0, train_size=.7, shuffle=True)\n",
    "#introducing early stopping for overfitting\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "#training model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[earlyStopping])\n",
    "test_loss, test_acc = model.evaluate(images, labelsCategorical, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"MAX Validation Accuracy\", max(list(history.history['val_accuracy'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "higher early stopping and no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 72ms/step - accuracy: 0.2482 - loss: 2.0242 - val_accuracy: 0.4243 - val_loss: 1.6284\n",
      "Epoch 2/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.4807 - loss: 1.4614 - val_accuracy: 0.4683 - val_loss: 1.4977\n",
      "Epoch 3/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 71ms/step - accuracy: 0.5577 - loss: 1.2340 - val_accuracy: 0.5033 - val_loss: 1.4618\n",
      "Epoch 4/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.6447 - loss: 1.0311 - val_accuracy: 0.5000 - val_loss: 1.4725\n",
      "Epoch 5/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.6918 - loss: 0.8751 - val_accuracy: 0.4970 - val_loss: 1.5703\n",
      "Epoch 6/50\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 74ms/step - accuracy: 0.7535 - loss: 0.7203 - val_accuracy: 0.4910 - val_loss: 1.6072\n",
      "313/313 - 6s - 20ms/step - accuracy: 0.6083 - loss: 1.1399\n",
      "Test Accuracy: 0.6083\n",
      "MAX Validation Accuracy 0.503333330154419\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=3, activation=\"relu\", input_shape=imageShape))\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#compile model using accuracy\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labelsCategorical, random_state=0, train_size=.7, shuffle=True)\n",
    "#introducing early stopping for overfitting\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "#training model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[earlyStopping])\n",
    "test_loss, test_acc = model.evaluate(images, labelsCategorical, verbose=2)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"MAX Validation Accuracy\", max(list(history.history['val_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
